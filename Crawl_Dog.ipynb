{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import InvalidArgumentException\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('https://www.chotot.com/mua-ban-cho-tp-ho-chi-minh/robots.txt')\n",
    "rp.read()\n",
    "\n",
    "url = 'https://www.chotot.com/mua-ban-cho-tp-ho-chi-minh'\n",
    "rp.can_fetch('*', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_one_dog(link):\n",
    "    print('https://www.chotot.com' + link)\n",
    "    driver = webdriver.Firefox()\n",
    "    try:\n",
    "        driver.get('https://www.chotot.com' + link)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        price = np.nan\n",
    "        description = np.nan\n",
    "        breed = np.nan        \n",
    "        age = np.nan        \n",
    "        size = np.nan\n",
    "        address = np.nan\n",
    "        # phone_num = np.nan\n",
    "\n",
    "        price_tag = soup.find('span', attrs = {'itemprop': 'price'})\n",
    "        price = price_tag.text if price_tag else np.nan\n",
    "\n",
    "        description_tag = soup.find('p', attrs = {'class': 'AdDecription_adBody__qp2KG'})\n",
    "        description = description_tag.text if description_tag else np.nan\n",
    "\n",
    "        breed_tag = soup.find('span', attrs = {'itemprop': 'pet_breed'})\n",
    "        breed = breed_tag.text if breed_tag else np.nan\n",
    "\n",
    "        age_tag = soup.find('span', attrs = {'itemprop': 'pet_age'})\n",
    "        age = age_tag.text if age_tag else np.nan\n",
    "\n",
    "        size_tag = soup.find('span', attrs = {'itemprop': 'pet_size'})\n",
    "        size = size_tag.text if size_tag else np.nan\n",
    "\n",
    "        address_tag = soup.find('div', attrs={'class':'media-body media-middle AdParam_address__5wp1F'})\n",
    "        address = address_tag.text if address_tag else np.nan\n",
    "\n",
    "        # # Click the button to show the phone number\n",
    "        # driver.execute_script(\"var element = document.querySelector('.aw__s1cdo2zu'); if (element) element.parentNode.removeChild(element);\")\n",
    "        # button = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.CLASS_NAME, 'ShowPhoneButton_icon__wsnZ5')))\n",
    "        # driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "        # button.click()\n",
    "        # soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        # # Wait for the phone number to load (adjust the timeout as needed)\n",
    "        # phone_num_tag = soup.find('div', attrs = {'class': 'ShowPhoneButton_phoneButton__p5Cvt ShowPhoneButton_phoneClicked__IxuR6'})\n",
    "        # phone_num = phone_num_tag.text if phone_num_tag else np.nan\n",
    "\n",
    "        driver.quit()\n",
    "        return price, description, breed, age, size, address\n",
    "    except InvalidArgumentException:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more dogs to crawl\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "param = '?page='\n",
    "# index_page = 123\n",
    "index_page = 1\n",
    "while(True):\n",
    "    driver = webdriver.Firefox()\n",
    "    try:\n",
    "        driver.get(url + param + str(index_page))\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        not_found = soup.find('div', attrs={'class': 'NotFound_content__KtIbC'})\n",
    "        if not_found is not None:\n",
    "            print('No more dogs to crawl')\n",
    "            break\n",
    "\n",
    "        dogs_links = soup.find_all('div', attrs={'role' : 'button'})\n",
    "        for i in dogs_links:\n",
    "            price, description, breed, age, size, address = crawl_one_dog(i.find('a')['href'])\n",
    "            \n",
    "            data = pd.DataFrame({\n",
    "                'price': [price],\n",
    "                'description': [description],\n",
    "                'breed': [breed],\n",
    "                'age': [age],\n",
    "                'size': [size],\n",
    "                'address': [address],\n",
    "                # 'phone_num': [phone_num]\n",
    "            })\n",
    "            df = pd.concat([df, data], axis = 0)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    index_page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Dog.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
